# cursor_control_using_hand_and_face_gesture
A computer vision-based system that enables mouse control using hand and head gestures via webcam. Built with Python, OpenCV, and MediaPipe, it allows real-time gesture recognition for cursor movement and clicks. Ideal for accessibility, hands-free control, and experimental human-computer interaction.

ğŸ“Œ Features
ğŸ¯ Real-time hand and head gesture detection

ğŸ–±ï¸ Cursor movement using hand position

ğŸ–ï¸ Click and drag operations via custom gestures

ğŸ‘¤ Head movement tracking for additional control

âš¡ Works with standard webcams

ğŸ§  Built using Python, OpenCV, and MediaPipe

ğŸ› ï¸ Technologies Used
Python 3.x

OpenCV â€“ video processing

MediaPipe â€“ hand and face landmark detection

PyAutoGUI â€“ cursor and click automation

Dlib / FaceMesh (optional) â€“ head gesture enhancement

ğŸš€ Getting Started
Prerequisites
Python 3.7 or above

Webcam (built-in or external)


Installation
git clone https://github.com/adnanfuzail/cursor_control_using_hand_and_head_gesture.git
cd cursor_control_using_hand_and_head_gesture


ğŸ“· How It Works
Captures live webcam feed

Detects hand and head landmarks using MediaPipe

Translates gestures into mouse movements or clicks

Sends commands using PyAutoGUI

ğŸ¯ Use Cases
Accessibility for users with mobility impairments

Hands-free computing in sterile environments

Gesture-based HCI research

AR/VR prototype interfaces

ğŸ“– Future Improvements
Add gesture customization

Improve gesture accuracy

Integrate voice control

Support multi-monitor setups

ğŸ™‹â€â™‚ï¸ Contributors
Adnan Fuzail â€“ Developer

ğŸ“„ License
This project is licensed under the MIT License â€“ see the LICENSE file for details.
